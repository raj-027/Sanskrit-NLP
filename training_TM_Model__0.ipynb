{
  "nbformat": 4,
  "nbformat_minor": 0,
  "metadata": {
    "colab": {
      "provenance": [],
      "gpuType": "T4",
      "mount_file_id": "1X5XZ7VunsrDuwdnz4c48J97NC1jwmd3r",
      "authorship_tag": "ABX9TyM28VxP4oWFyt6bT1asjuTv",
      "include_colab_link": true
    },
    "kernelspec": {
      "name": "python3",
      "display_name": "Python 3"
    },
    "language_info": {
      "name": "python"
    },
    "accelerator": "GPU"
  },
  "cells": [
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "view-in-github",
        "colab_type": "text"
      },
      "source": [
        "<a href=\"https://colab.research.google.com/github/raj-027/Sanskrit-NLP/blob/main/training_TM_Model__0.ipynb\" target=\"_parent\"><img src=\"https://colab.research.google.com/assets/colab-badge.svg\" alt=\"Open In Colab\"/></a>"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "BPfWNGtKRcMW"
      },
      "outputs": [],
      "source": [
        "import torch\n",
        "import torch.nn as nn\n",
        "import torch.nn.functional as F\n",
        "from torch.utils.data import Dataset, DataLoader\n",
        "import pandas as pd\n",
        "import numpy as np\n",
        "import unicodedata\n",
        "from sklearn.model_selection import train_test_split\n"
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "def normalize_phoneme(p):\n",
        "    p = p.strip()\n",
        "    p = unicodedata.normalize(\"NFC\", p)\n",
        "\n",
        "    # remove zero-width chars\n",
        "    p = p.replace(\"\\u200c\", \"\").replace(\"\\u200d\", \"\")\n",
        "\n",
        "\n",
        "\n",
        "    return p"
      ],
      "metadata": {
        "id": "kdyH0EV8AtsT"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "DEVANAGARI_MATRAS = {\n",
        "    \"‡§æ\": \"‡§Ü\", \"‡§ø\": \"‡§á\", \"‡•Ä\": \"‡§à\", \"‡•Å\": \"‡§â\", \"‡•Ç\": \"‡§ä\",\n",
        "    \"‡•É\": \"‡§ã\", \"‡•Ñ\": \"‡•†\", \"‡•¢\": \"‡§å\", \"‡•£\": \"‡•°\",\n",
        "    \"‡•á\": \"‡§è\", \"‡•à\": \"‡§ê\", \"‡•ã\": \"‡§ì\", \"‡•å\": \"‡§î\",\n",
        "}\n",
        "\n",
        "# independent vowels set\n",
        "DEVANAGARI_VOWELS = set(list(\"‡§Ö‡§Ü‡§á‡§à‡§â‡§ä‡§ã‡•†‡§å‡•°‡§è‡§ê‡§ì‡§î\"))\n",
        "\n",
        "# consonants range roughly (‡§ï..‡§π) ‚Äî we'll treat these as consonants\n",
        "# include nukta & other combining marks handled separately\n",
        "DEVANAGARI_CONSONANTS = set(list(\n",
        "    \"‡§ï‡§ñ‡§ó‡§ò‡§ô‡§ö‡§õ‡§ú‡§ù‡§û‡§ü‡§†‡§°‡§¢‡§£‡§§‡§•‡§¶‡§ß‡§®‡§™‡§´‡§¨‡§≠‡§Æ‡§Ø‡§±‡§≤‡§µ‡§∂‡§∑‡§∏‡§π\"\n",
        "))\n",
        "# add retroflex/rule variants if needed (adjust per data)\n",
        "# Halant, nukta, anusvara, visarga\n",
        "HALANT = \"\\u094D\"     # ‡•ç\n",
        "NUKTA = \"\\u093C\"      # ‡§º\n",
        "ANUSVARA = \"‡§Ç\"\n",
        "VISARGA = \"‡§É\"\n",
        "CANDRABINDU = \"‡§Å\"\n",
        "\n",
        "PHONETIC_MODIFIERS = {ANUSVARA, VISARGA, CANDRABINDU}\n",
        "\n",
        "def akshara_to_phonemes(token):\n",
        "\n",
        "    token = unicodedata.normalize(\"NFC\", token.strip())\n",
        "    phonemes = []\n",
        "    i = 0\n",
        "    chars = list(token)\n",
        "\n",
        "    while i < len(chars):\n",
        "        ch = chars[i]\n",
        "\n",
        "        # independent vowel\n",
        "        if ch in DEVANAGARI_VOWELS:\n",
        "            phonemes.append(ch)\n",
        "            i += 1\n",
        "            continue\n",
        "\n",
        "        # modifier symbols that act like separate phonemes (anusvara/visarga)\n",
        "        if ch in PHONETIC_MODIFIERS:\n",
        "            phonemes.append(ch)\n",
        "            i += 1\n",
        "            continue\n",
        "\n",
        "        # consonant (including possible nukta immediately after)\n",
        "        if ch in DEVANAGARI_CONSONANTS:\n",
        "            base = ch\n",
        "            i += 1\n",
        "            # nukta (rare) e.g. ‡§ï‡§º\n",
        "            if i < len(chars) and chars[i] == NUKTA:\n",
        "                base = base + chars[i]\n",
        "                i += 1\n",
        "\n",
        "            # halant means explicit consonant without inherent vowel\n",
        "            if i < len(chars) and chars[i] == HALANT:\n",
        "                # append base (consonant) only, skip halant\n",
        "                phonemes.append(base)\n",
        "                i += 1\n",
        "                continue\n",
        "\n",
        "            # vowel matra attached? map to independent vowel and append base+vowel\n",
        "            if i < len(chars) and chars[i] in DEVANAGARI_MATRAS:\n",
        "                mat = chars[i]\n",
        "                vowel = DEVANAGARI_MATRAS[mat]\n",
        "                phonemes.append(base)\n",
        "                phonemes.append(vowel)\n",
        "                i += 1\n",
        "                continue\n",
        "\n",
        "            # If no matra/halant follows, append consonant (in many phonemic analyses\n",
        "            # the inherent vowel '‡§Ö' is present. Depending on your phoneme vectors you\n",
        "            # may want to append '‡§Ö' as well. Here we append the consonant alone,\n",
        "            # which matches a common phoneme mapping where consonant segments are separate.)\n",
        "            phonemes.append(base)\n",
        "            continue\n",
        "\n",
        "        # standalone matra (shouldn't usually happen), convert to vowel\n",
        "        if ch in DEVANAGARI_MATRAS:\n",
        "            phonemes.append(DEVANAGARI_MATRAS[ch])\n",
        "            i += 1\n",
        "            continue\n",
        "\n",
        "        # otherwise: unknown char, append as-is (fallback)\n",
        "        phonemes.append(ch)\n",
        "        i += 1\n",
        "\n",
        "    return phonemes\n"
      ],
      "metadata": {
        "id": "6gzTk7Ew4vGw"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "device = torch.device(\"cuda\" if torch.cuda.is_available() else \"cpu\")\n",
        "print(\"Using device:\", device)\n"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "0vcNIRrYaNtO",
        "outputId": "09bc605a-f54f-4ef4-a29a-12693ae1c25a"
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Using device: cuda\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "## Loading Phonetic Characters Vectors\n",
        "\n",
        "def load_phone_vectors(csv_path):\n",
        "    df = pd.read_csv(\"/content/drive/MyDrive/Sanskrit NLP/sanskrit_phoneme_vectors (1).csv\")\n",
        "\n",
        "    phoneme_col = df.columns[0]\n",
        "    feature_cols = df.columns[1:]\n",
        "\n",
        "    df[feature_cols] = (\n",
        "        df[feature_cols]\n",
        "        .astype(str)\n",
        "        .replace(\"‚àí\", \"-\", regex=True)\n",
        "        .replace(r\"^\\s*$\", \"0\", regex=True)\n",
        "    )\n",
        "\n",
        "    df[feature_cols] = df[feature_cols].apply(\n",
        "        lambda col: pd.to_numeric(col, errors=\"coerce\")\n",
        "    ).fillna(0.0)\n",
        "\n",
        "    def to_ternary(x):\n",
        "        if x > 0:\n",
        "            return 1.0\n",
        "        elif x < 0:\n",
        "            return -1.0\n",
        "        else:\n",
        "            return 0.0\n",
        "\n",
        "    df[feature_cols] = df[feature_cols].applymap(to_ternary)\n",
        "\n",
        "    feature_matrix = df[feature_cols].to_numpy(dtype=np.float32)\n",
        "\n",
        "    unique_vals = set(np.unique(feature_matrix))\n",
        "    assert unique_vals.issubset({-1.0, 0.0, 1.0}), \\\n",
        "        f\"Non-ternary values found: {unique_vals}\"\n",
        "\n",
        "    phoneme_to_vec = {}\n",
        "    for i, phoneme in enumerate(df[phoneme_col]):\n",
        "        phoneme = str(phoneme).strip()\n",
        "        phoneme_to_vec[phoneme] = torch.from_numpy(feature_matrix[i])\n",
        "\n",
        "    panphon_dim = feature_matrix.shape[1]\n",
        "    return phoneme_to_vec, panphon_dim\n"
      ],
      "metadata": {
        "id": "4kuii4BOYUZX"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "\n",
        "phoneme_to_vec, dim = load_phone_vectors(\"/content/drive/MyDrive/Sanskrit NLP/sanskrit_phoneme_vectors (1).csv\")\n",
        "\n",
        "v = phoneme_to_vec[list(phoneme_to_vec.keys())[0]]\n",
        "print(v)\n",
        "print(torch.unique(v))\n"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "q3gZQjgqFj4S",
        "outputId": "63a0fcd1-a270-45c8-d6e1-bb0b21ff7c20"
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "tensor([ 0.,  0.,  0.,  0.,  0.,  0.,  0.,  0.,  0.,  0.,  0.,  0.,  0.,  0.,\n",
            "         0.,  0.,  0.,  0.,  0.,  0.,  0., -1., -1.,  1., -1.,  1., -1., -1.,\n",
            "         1.,  0.,  0., -1., -1., -1.])\n",
            "tensor([-1.,  0.,  1.])\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "/tmp/ipython-input-1668255932.py:31: FutureWarning: DataFrame.applymap has been deprecated. Use DataFrame.map instead.\n",
            "  df[feature_cols] = df[feature_cols].applymap(to_ternary)\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "def load_triplets(csv_path):\n",
        "    df = pd.read_csv(\"/content/drive/MyDrive/Sanskrit NLP/triplet_183422_RV_terms.csv\")\n",
        "\n",
        "    triplets = []\n",
        "    for _, row in df.iterrows():\n",
        "        triplets.append({\n",
        "            \"anchor\": row[\"anchor\"].split(),\n",
        "            \"positive\": row[\"positive\"].split(),\n",
        "            \"negative\": row[\"negative\"].split()\n",
        "        })\n",
        "    return triplets\n",
        "    type(triplets)\n",
        "    type(triplets[0])\n",
        "    type(triplets[0][\"anchor\"])\n",
        "    type(triplets[0][\"anchor\"][0])\n",
        "\n"
      ],
      "metadata": {
        "id": "4Dq29HdaVkVQ"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "triplets = load_triplets(\"/content/drive/MyDrive/Sanskrit NLP/triplet_183422_RV_terms.csv\")\n",
        "\n",
        "for i in range(3):\n",
        "    print(triplets[i])\n"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "r8FoFHYGxT7D",
        "outputId": "9c30bf68-edb2-431c-c5bb-df364cf548d6"
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "{'anchor': ['‡§π‡§ø‡§Ç‡§∏‡•ç‡§∞‡§æ'], 'positive': ['‡§Æ‡§Ç‡§∏‡•Ä‡§∞‡§§'], 'negative': ['‡§Ö‡§™‡§ø‡•ë‡§Ω‡§á‡§µ']}\n",
            "{'anchor': ['‡§¶‡•Å‡§π‡§ø‡§§‡§É'], 'positive': ['‡§¨‡•É‡§π‡§§‡§É'], 'negative': ['‡§∂‡•Å‡•í‡§∑‡•á‡•í']}\n",
            "{'anchor': ['‡§ã‡§£‡§Æ‡•ç'], 'positive': ['‡§ã‡§£‡§É'], 'negative': ['‡§™‡§æ‡•í‡§•']}\n"
          ]
        }
      ]
    },
    {
      "cell_type": "markdown",
      "source": [
        "Dataset Class (CSV -> tensors)"
      ],
      "metadata": {
        "id": "fxDoW3mKVrTr"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "class TripletPhoneticDataset(torch.utils.data.Dataset):\n",
        "    def __init__(self, triplets, phoneme_to_vec, dim):\n",
        "\n",
        "        self.triplets = triplets\n",
        "        self.phoneme_to_vec = phoneme_to_vec\n",
        "        self.dim = dim\n",
        "        self.zero = torch.zeros(dim, dtype=torch.float32)\n",
        "\n",
        "    def encode(self, token_list):\n",
        "        \"\n",
        "        if isinstance(token_list, str):\n",
        "            token_list = [token_list]\n",
        "\n",
        "        phoneme_seq = []\n",
        "        for tok in token_list:\n",
        "\n",
        "            if isinstance(tok, str) and \" \" in tok:\n",
        "                subtoks = tok.strip().split()\n",
        "                for st in subtoks:\n",
        "                    phoneme_seq.extend(akshara_to_phonemes(st))\n",
        "            else:\n",
        "                phoneme_seq.extend(akshara_to_phonemes(tok))\n",
        "\n",
        "        vectors = []\n",
        "        for p in phoneme_seq:\n",
        "            if p in self.phoneme_to_vec:\n",
        "                vectors.append(self.phoneme_to_vec[p].float())\n",
        "            else:\n",
        "                vectors.append(self.zero)\n",
        "\n",
        "        if len(vectors) == 0:\n",
        "            raise RuntimeError(\"Empty phoneme sequence after segmentation!\")\n",
        "\n",
        "        return torch.stack(vectors)  # shape (L, dim)\n",
        "\n",
        "    def __len__(self):\n",
        "        return len(self.triplets)\n",
        "\n",
        "    def __getitem__(self, idx):\n",
        "        t = self.triplets[idx]\n",
        "        return (\n",
        "            self.encode(t[\"anchor\"]),\n",
        "            self.encode(t[\"positive\"]),\n",
        "            self.encode(t[\"negative\"])\n",
        "        )"
      ],
      "metadata": {
        "id": "59n8_qwGVyKs"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "train_triplets, val_triplets = train_test_split(\n",
        "    triplets,\n",
        "    test_size=0.2,\n",
        "    random_state=42,\n",
        "    shuffle=True\n",
        ")\n",
        "\n",
        "print(f\"Train triplets: {len(train_triplets)}\")\n",
        "print(f\"Val triplets:   {len(val_triplets)}\")"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "V0tSLFsdCYT9",
        "outputId": "df66834b-f8b4-47cf-eb53-a090701adfc2"
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Train triplets: 16000\n",
            "Val triplets:   4000\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "train_dataset = TripletPhoneticDataset(\n",
        "    train_triplets, phoneme_to_vec, dim\n",
        ")\n",
        "\n",
        "val_dataset = TripletPhoneticDataset(\n",
        "    val_triplets, phoneme_to_vec, dim\n",
        ")\n"
      ],
      "metadata": {
        "id": "12HAqAR2C2_p"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "dataset = TripletPhoneticDataset(triplets, phoneme_to_vec, dim)\n",
        "\n",
        "a, p, n = dataset[0]\n",
        "\n",
        "print(a.shape, p.shape, n.shape)\n",
        "print(a)\n"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "_yz0oF2t0GaM",
        "outputId": "f2485ad5-f6be-42fa-82ee-729ee9a73c69"
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "torch.Size([6, 34]) torch.Size([6, 34]) torch.Size([7, 34])\n",
            "tensor([[ 1., -1., -1.,  0.,  1.,  0.,  0.,  0.,  0.,  0.,  0.,  0.,  0.,  0.,\n",
            "          0.,  0.,  0.,  0.,  0.,  0.,  1.,  0.,  0.,  0.,  0.,  0.,  0.,  0.,\n",
            "          0.,  0.,  0.,  0.,  0.,  0.],\n",
            "        [ 0.,  0.,  0.,  0.,  0.,  0.,  0.,  0.,  0.,  0.,  0.,  0.,  0.,  0.,\n",
            "          0.,  0.,  0.,  0.,  0.,  0.,  0.,  1., -1., -1., -1., -1.,  1., -1.,\n",
            "         -1.,  0.,  0., -1., -1., -1.],\n",
            "        [ 0.,  0.,  0.,  0.,  0.,  0.,  0.,  0.,  0.,  0.,  0.,  0.,  0.,  0.,\n",
            "          0.,  0.,  0.,  0.,  0.,  0.,  0.,  0.,  0.,  0.,  0.,  0.,  0.,  0.,\n",
            "          0.,  0.,  0.,  0.,  0., -1.],\n",
            "        [-1., -1., -1.,  0.,  1.,  0.,  0.,  0.,  0.,  0.,  0.,  0.,  0.,  1.,\n",
            "          0.,  0.,  0.,  0.,  0.,  0.,  0.,  0.,  0.,  0.,  0.,  0.,  0.,  0.,\n",
            "          0.,  0.,  0.,  0.,  0.,  0.],\n",
            "        [ 1., -1., -1.,  0.,  0.,  0.,  0.,  0.,  1.,  0.,  0.,  0.,  0.,  0.,\n",
            "          1.,  0.,  0.,  0.,  0.,  0.,  0.,  0.,  0.,  0.,  0.,  0.,  0.,  0.,\n",
            "          0.,  0.,  0.,  0.,  0.,  0.],\n",
            "        [ 0.,  0.,  0.,  0.,  0.,  0.,  0.,  0.,  0.,  0.,  0.,  0.,  0.,  0.,\n",
            "          0.,  0.,  0.,  0.,  0.,  0.,  0., -1., -1.,  1., -1.,  1., -1., -1.,\n",
            "          1.,  0.,  0., -1.,  1., -1.]])\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "# Check unique values in a phoneme vector\n",
        "vec = phoneme_to_vec[list(phoneme_to_vec.keys())[0]]\n",
        "print(torch.unique(vec))\n"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "so5oLVV3FT6P",
        "outputId": "a7204813-5ef8-49e2-a0af-77df76b39a7c"
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "tensor([-1.,  0.,  1.])\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [],
      "metadata": {
        "id": "EZP_UcyDFV-l"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "print(\"Triplet phoneme:\", repr(dataset.triplets[0][\"anchor\"][0]))\n",
        "print(\"Keys sample:\", list(phoneme_to_vec.keys())[:10])\n"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "s2NrhalH3L7O",
        "outputId": "9af4b136-ed47-431b-efe4-c454c028fdbb"
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Triplet phoneme: '‡§π‡§ø‡§Ç‡§∏‡•ç‡§∞‡§æ'\n",
            "Keys sample: ['‡§Ö', '‡§Ü', '‡§á', '‡§à', '‡§â', '‡§ä', '‡§ã', '‡•†', '‡§å', '‡•°']\n"
          ]
        }
      ]
    },
    {
      "cell_type": "markdown",
      "source": [
        "collate function -> padding sequences"
      ],
      "metadata": {
        "id": "ZO2b1QLlV4VY"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "def collate_fn(batch):\n",
        "    def pad(seqs):\n",
        "        lengths = torch.tensor([s.shape[0] for s in seqs])\n",
        "        max_len = lengths.max()\n",
        "        padded = torch.zeros(len(seqs), max_len, seqs[0].shape[1])\n",
        "\n",
        "        for i, s in enumerate(seqs):\n",
        "            padded[i, :s.shape[0]] = s\n",
        "        return padded, lengths\n",
        "\n",
        "    A, P, N = zip(*batch)\n",
        "    A, len_A = pad(A)\n",
        "    P, len_P = pad(P)\n",
        "    N, len_N = pad(N)\n",
        "\n",
        "    return A, len_A, P, len_P, N, len_N\n"
      ],
      "metadata": {
        "id": "PvxY_R-DV3T5"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "BiLSTM Encoder"
      ],
      "metadata": {
        "id": "At19TYl6V_C5"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "class PhoneticEncoder(nn.Module):\n",
        "    def __init__(self, input_dim, hidden_dim=256,layers = 2, proj_dim=128):\n",
        "        super().__init__()\n",
        "        self.lstm = nn.LSTM(\n",
        "            input_dim,\n",
        "            hidden_dim,\n",
        "            num_layers=2,\n",
        "            batch_first=True,\n",
        "            bidirectional=True\n",
        "        )\n",
        "        self.proj = nn.Linear(hidden_dim * 2, proj_dim)\n",
        "\n",
        "    def forward(self, x, lengths):\n",
        "        packed = nn.utils.rnn.pack_padded_sequence(\n",
        "            x, lengths.cpu(), batch_first=True, enforce_sorted=False\n",
        "        )\n",
        "        out, _ = self.lstm(packed)\n",
        "        out, _ = nn.utils.rnn.pad_packed_sequence(out, batch_first=True)\n",
        "\n",
        "        mask = torch.arange(out.size(1)).to(lengths.device)[None, :] < lengths[:, None]\n",
        "        mask = mask.unsqueeze(-1)\n",
        "        pooled = (out * mask).sum(dim=1) / lengths.unsqueeze(1)\n",
        "\n",
        "        return self.proj(pooled)\n",
        "\n"
      ],
      "metadata": {
        "id": "wSLCpvL7WB2p"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "Triplet Model (Shared Encoder)"
      ],
      "metadata": {
        "id": "retV4W3kWE4t"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "class TripletModel(nn.Module):\n",
        "    def __init__(self, encoder):\n",
        "        super().__init__()\n",
        "        self.encoder = encoder\n",
        "\n",
        "    def forward(self, A, len_A, P, len_P, N, len_N):\n",
        "      emb_A = F.normalize(self.encoder(A, len_A), dim=1)\n",
        "      emb_P = F.normalize(self.encoder(P, len_P), dim=1)\n",
        "      emb_N = F.normalize(self.encoder(N, len_N), dim=1)\n",
        "      return emb_A, emb_P, emb_N\n",
        "\n",
        "\n"
      ],
      "metadata": {
        "id": "V7G5KyVzWIsd"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "train_loader = DataLoader(\n",
        "    train_dataset,\n",
        "    batch_size=32,\n",
        "    shuffle=True,\n",
        "    drop_last=True\n",
        ")\n",
        "\n",
        "val_loader = DataLoader(\n",
        "    val_dataset,\n",
        "    batch_size=32,\n",
        "    shuffle=False,\n",
        "    drop_last=False\n",
        ")"
      ],
      "metadata": {
        "id": "el8imkfLC-00"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "Training Loop"
      ],
      "metadata": {
        "id": "CEs63U9eWM-S"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "#Loss function\n",
        "\n",
        "def triplet_margin_loss(anchor, positive, negative, margin):\n",
        "    \"\"\"\n",
        "    anchor, positive, negative: tensors of shape [batch, embedding_dim]\n",
        "    margin: float (Œ±)\n",
        "    \"\"\"\n",
        "\n",
        "    # Euclidean distances\n",
        "    d_ap = torch.norm(anchor - positive, p=2, dim=1)\n",
        "    d_an = torch.norm(anchor - negative, p=2, dim=1)\n",
        "\n",
        "    # Triplet loss\n",
        "    loss = torch.clamp(margin + d_ap - d_an, min=0.0)\n",
        "\n",
        "    return loss.mean()\n"
      ],
      "metadata": {
        "id": "PYpoUjTEEG8N"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "def train(\n",
        "    model,\n",
        "    train_dataloader,\n",
        "    val_dataloader,\n",
        "    epochs=200,\n",
        "    lr=1e-3,\n",
        "    margin=0.5,\n",
        "    device=None\n",
        "):\n",
        "    if device is None:\n",
        "        device = torch.device(\"cuda\" if torch.cuda.is_available() else \"cpu\")\n",
        "\n",
        "    model.to(device)\n",
        "    optimizer = torch.optim.AdamW(model.parameters(), lr=lr)\n",
        "\n",
        "    global best_val_loss, patience_counter, patience\n",
        "\n",
        "    for epoch in range(1, epochs + 1):\n",
        "        model.train()\n",
        "        train_loss = 0.0\n",
        "\n",
        "        for a, len_A, p, len_P, n, len_N in train_dataloader:\n",
        "            a, p, n = a.to(device), p.to(device), n.to(device)\n",
        "            len_A, len_P, len_N = len_A.to(device), len_P.to(device), len_N.to(device)\n",
        "\n",
        "            optimizer.zero_grad()\n",
        "\n",
        "            emb_A, emb_P, emb_N = model(a, len_A, p, len_P, n, len_N)\n",
        "\n",
        "            loss = triplet_margin_loss(emb_A, emb_P, emb_N, margin)\n",
        "            loss.backward()\n",
        "            optimizer.step()\n",
        "\n",
        "            train_loss += loss.item()\n",
        "\n",
        "        train_loss /= len(train_dataloader)\n",
        "\n",
        "        val_loss = evaluate(model, val_dataloader, triplet_margin_loss, device, margin)\n",
        "\n",
        "        print(\n",
        "            f\"Epoch {epoch:03d} | \"\n",
        "            f\"Train Loss: {train_loss:.4f} | \"\n",
        "            f\"Val Loss: {val_loss:.4f}\"\n",
        "        )\n",
        "\n",
        "        if val_loss < best_val_loss:\n",
        "            best_val_loss = val_loss\n",
        "            patience_counter = 0\n",
        "\n",
        "            torch.save(\n",
        "                model.encoder.state_dict(),\n",
        "                \"sanskrit_phonetic_TML_model.pkl\"\n",
        "            )\n",
        "\n",
        "            print(\"Best model saved\")\n",
        "\n",
        "        else:\n",
        "            patience_counter += 1\n",
        "            print(f\" No improvement ({patience_counter}/{patience})\")\n",
        "\n",
        "            if patience_counter >= patience:\n",
        "                print(\"Early stopping triggered (overfitting detected)\")\n",
        "                break"
      ],
      "metadata": {
        "id": "j7Q9V1geWLei"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "def evaluate(model, dataloader, loss_fn, device, margin):\n",
        "    model.eval()\n",
        "    total_loss = 0.0\n",
        "    count = 0\n",
        "\n",
        "    with torch.no_grad():\n",
        "        for a, len_A, p, len_P, n, len_N in dataloader:\n",
        "            a, p, n = a.to(device), p.to(device), n.to(device)\n",
        "            len_A, len_P, len_N = len_A.to(device), len_P.to(device), len_N.to(device)\n",
        "\n",
        "            emb_A, emb_P, emb_N = model(a, len_A, p, len_P, n, len_N)\n",
        "\n",
        "            loss = loss_fn(emb_A, emb_P, emb_N, margin)\n",
        "            total_loss += loss.item()\n",
        "            count += 1\n",
        "\n",
        "    return total_loss / count"
      ],
      "metadata": {
        "id": "6zxu-bDYDKjc"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "patience = 9\n",
        "best_val_loss = float(\"inf\")\n",
        "patience_counter = 0\n"
      ],
      "metadata": {
        "id": "eKHneDwEDOuN"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "PHONE_VEC_CSV = \"/content/drive/MyDrive/Sanskrit NLP/sanskrit_phoneme_vectors (1).csv\"\n",
        "TRIPLETS_CSV = \"/content/drive/MyDrive/Sanskrit NLP/panphon_triplets_183422_RV terms.csv\"\n",
        "\n",
        "# Load data\n",
        "phone_to_vec, PANPHON_DIM = load_phone_vectors(PHONE_VEC_CSV)\n",
        "\n",
        "\n",
        "train_loader = DataLoader(\n",
        "    train_dataset,\n",
        "    batch_size=32,\n",
        "    collate_fn=collate_fn,\n",
        "    drop_last=True\n",
        ")\n",
        "\n",
        "val_loader = DataLoader(\n",
        "    val_dataset,\n",
        "    batch_size=32,\n",
        "    shuffle=False,\n",
        "    collate_fn=collate_fn,\n",
        "    drop_last=False\n",
        ")\n",
        "\n",
        "# Model\n",
        "encoder = PhoneticEncoder(\n",
        "    input_dim=PANPHON_DIM,\n",
        "    hidden_dim=256,\n",
        "    layers=2,\n",
        "    proj_dim = 128\n",
        ")\n",
        "model = TripletModel(encoder)\n",
        "\n",
        "# Train\n",
        "train(\n",
        "    model,\n",
        "    train_loader,\n",
        "    val_loader,\n",
        "    epochs=200,\n",
        "    lr=1e-3,\n",
        "    margin=0.3,\n",
        "    device = device\n",
        ")"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "IknH8hNLWVNW",
        "outputId": "b5262147-f202-47ef-8782-3e4ee1faccb9"
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "/tmp/ipython-input-1668255932.py:31: FutureWarning: DataFrame.applymap has been deprecated. Use DataFrame.map instead.\n",
            "  df[feature_cols] = df[feature_cols].applymap(to_ternary)\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Epoch 001 | Train Loss: 0.0094 | Val Loss: 0.0058\n",
            "   ‚úì Best model saved\n",
            "Epoch 002 | Train Loss: 0.0039 | Val Loss: 0.0032\n",
            "   ‚úì Best model saved\n",
            "Epoch 003 | Train Loss: 0.0024 | Val Loss: 0.0023\n",
            "   ‚úì Best model saved\n",
            "Epoch 004 | Train Loss: 0.0012 | Val Loss: 0.0018\n",
            "   ‚úì Best model saved\n",
            "Epoch 005 | Train Loss: 0.0013 | Val Loss: 0.0019\n",
            "   ‚úó No improvement (1/9)\n",
            "Epoch 006 | Train Loss: 0.0010 | Val Loss: 0.0025\n",
            "   ‚úó No improvement (2/9)\n",
            "Epoch 007 | Train Loss: 0.0010 | Val Loss: 0.0031\n",
            "   ‚úó No improvement (3/9)\n",
            "Epoch 008 | Train Loss: 0.0008 | Val Loss: 0.0017\n",
            "   ‚úì Best model saved\n",
            "Epoch 009 | Train Loss: 0.0011 | Val Loss: 0.0046\n",
            "   ‚úó No improvement (1/9)\n",
            "Epoch 010 | Train Loss: 0.0007 | Val Loss: 0.0011\n",
            "   ‚úì Best model saved\n",
            "Epoch 011 | Train Loss: 0.0007 | Val Loss: 0.0010\n",
            "   ‚úì Best model saved\n",
            "Epoch 012 | Train Loss: 0.0004 | Val Loss: 0.0018\n",
            "   ‚úó No improvement (1/9)\n",
            "Epoch 013 | Train Loss: 0.0002 | Val Loss: 0.0012\n",
            "   ‚úó No improvement (2/9)\n",
            "Epoch 014 | Train Loss: 0.0006 | Val Loss: 0.0009\n",
            "   ‚úì Best model saved\n",
            "Epoch 015 | Train Loss: 0.0003 | Val Loss: 0.0007\n",
            "   ‚úì Best model saved\n",
            "Epoch 016 | Train Loss: 0.0003 | Val Loss: 0.0014\n",
            "   ‚úó No improvement (1/9)\n",
            "Epoch 017 | Train Loss: 0.0003 | Val Loss: 0.0009\n",
            "   ‚úó No improvement (2/9)\n",
            "Epoch 018 | Train Loss: 0.0003 | Val Loss: 0.0013\n",
            "   ‚úó No improvement (3/9)\n",
            "Epoch 019 | Train Loss: 0.0003 | Val Loss: 0.0007\n",
            "   ‚úó No improvement (4/9)\n",
            "Epoch 020 | Train Loss: 0.0001 | Val Loss: 0.0011\n",
            "   ‚úó No improvement (5/9)\n",
            "Epoch 021 | Train Loss: 0.0008 | Val Loss: 0.0008\n",
            "   ‚úó No improvement (6/9)\n",
            "Epoch 022 | Train Loss: 0.0003 | Val Loss: 0.0006\n",
            "   ‚úì Best model saved\n",
            "Epoch 023 | Train Loss: 0.0001 | Val Loss: 0.0010\n",
            "   ‚úó No improvement (1/9)\n",
            "Epoch 024 | Train Loss: 0.0002 | Val Loss: 0.0005\n",
            "   ‚úì Best model saved\n",
            "Epoch 025 | Train Loss: 0.0001 | Val Loss: 0.0008\n",
            "   ‚úó No improvement (1/9)\n",
            "Epoch 026 | Train Loss: 0.0001 | Val Loss: 0.0005\n",
            "   ‚úó No improvement (2/9)\n",
            "Epoch 027 | Train Loss: 0.0002 | Val Loss: 0.0008\n",
            "   ‚úó No improvement (3/9)\n",
            "Epoch 028 | Train Loss: 0.0002 | Val Loss: 0.0008\n",
            "   ‚úó No improvement (4/9)\n",
            "Epoch 029 | Train Loss: 0.0001 | Val Loss: 0.0004\n",
            "   ‚úì Best model saved\n",
            "Epoch 030 | Train Loss: 0.0002 | Val Loss: 0.0012\n",
            "   ‚úó No improvement (1/9)\n",
            "Epoch 031 | Train Loss: 0.0001 | Val Loss: 0.0006\n",
            "   ‚úó No improvement (2/9)\n",
            "Epoch 032 | Train Loss: 0.0001 | Val Loss: 0.0007\n",
            "   ‚úó No improvement (3/9)\n",
            "Epoch 033 | Train Loss: 0.0000 | Val Loss: 0.0003\n",
            "   ‚úì Best model saved\n",
            "Epoch 034 | Train Loss: 0.0000 | Val Loss: 0.0007\n",
            "   ‚úó No improvement (1/9)\n",
            "Epoch 035 | Train Loss: 0.0001 | Val Loss: 0.0008\n",
            "   ‚úó No improvement (2/9)\n",
            "Epoch 036 | Train Loss: 0.0002 | Val Loss: 0.0013\n",
            "   ‚úó No improvement (3/9)\n",
            "Epoch 037 | Train Loss: 0.0001 | Val Loss: 0.0006\n",
            "   ‚úó No improvement (4/9)\n",
            "Epoch 038 | Train Loss: 0.0000 | Val Loss: 0.0006\n",
            "   ‚úó No improvement (5/9)\n",
            "Epoch 039 | Train Loss: 0.0000 | Val Loss: 0.0006\n",
            "   ‚úó No improvement (6/9)\n",
            "Epoch 040 | Train Loss: 0.0000 | Val Loss: 0.0006\n",
            "   ‚úó No improvement (7/9)\n",
            "Epoch 041 | Train Loss: 0.0000 | Val Loss: 0.0006\n",
            "   ‚úó No improvement (8/9)\n",
            "Epoch 042 | Train Loss: 0.0000 | Val Loss: 0.0006\n",
            "   ‚úó No improvement (9/9)\n",
            "üõë Early stopping triggered (overfitting detected)\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "import torch\n",
        "import torch.nn.functional as F\n",
        "\n",
        "# Device\n",
        "device = torch.device(\"cuda\" if torch.cuda.is_available() else \"cpu\")\n",
        "\n",
        "encoder = PhoneticEncoder(\n",
        "    input_dim=PANPHON_DIM,\n",
        "    hidden_dim=256,\n",
        "    layers=2,\n",
        "    proj_dim=128\n",
        ")\n",
        "\n",
        "encoder.load_state_dict(torch.load(\"/content/sanskrit_phonetic_TML_model.pkl\", map_location=device))\n",
        "encoder.to(device)\n",
        "encoder.eval()\n",
        "\n",
        "print(\"Model loaded successfully\")\n"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "ngmnxnfnv_WS",
        "outputId": "9b5a1bca-ba47-404b-d1b3-cdc6d1bf7937"
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Model loaded successfully\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "def get_embedding(word):\n",
        "    \"\"\"\n",
        "    word: Sanskrit word (string)\n",
        "    returns: torch.Tensor (embedding_dim,)\n",
        "    \"\"\"\n",
        "    phonemes = akshara_to_phonemes(word)\n",
        "\n",
        "    vectors = [\n",
        "        phoneme_to_vec.get(p, torch.zeros(PANPHON_DIM))\n",
        "        for p in phonemes\n",
        "    ]\n",
        "\n",
        "    x = torch.stack(vectors).unsqueeze(0).to(device)  # (1, seq_len, dim)\n",
        "    lengths = torch.tensor([len(vectors)], device=device)\n",
        "\n",
        "    with torch.no_grad():\n",
        "        emb = encoder(x, lengths)\n",
        "\n",
        "    return emb.squeeze(0).cpu()   # shape: (128,)\n"
      ],
      "metadata": {
        "id": "DIQBoHm8wCU-"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "def euclidean_distance(e1, e2):\n",
        "    return torch.norm(e1 - e2, p=2).item()\n"
      ],
      "metadata": {
        "id": "RKaCy5zqwEh0"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "word_pairs = [\n",
        "    (\"‡§Æ‡§æ‡§¨‡§ø\", \"‡§Æ‡§æ‡§≠‡•Ä‡§≠\"),\n",
        "    (\"‡§á‡§π‡•à‡§ß‡§ø\", \"‡§Ø‡§π‡•á‡§ß‡•Ä\"),\n",
        "    (\"‡§á‡§∑‡•Å‡§∞‡§ø\", \"‡§á‡§∂‡•Ç‡§∞‡•Ä\"),\n",
        "    (\"‡§â‡§¶‡•á‡§£‡•Ä\", \"‡§â‡§ß‡•á‡§®‡§ø\"),\n",
        "    (\"‡§á‡§Ø‡§Æ‡§®‡•ç\", \"‡§Ø‡§Æ‡§®‡•ç‡§§\"),\n",
        "    (\"‡§®‡§µ‡§™‡•ç\", \"‡§™‡•ç‡§∞‡§æ‡§£\")\n",
        "\n",
        "]"
      ],
      "metadata": {
        "id": "cVWL5nZbxS07"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "def cosine_distance(e1, e2):\n",
        "\n",
        "    e1_norm = torch.norm(e1)\n",
        "    e2_norm = torch.norm(e2)\n",
        "    if e1_norm == 0 or e2_norm == 0:\n",
        "        return 1.0\n",
        "    cosine_sim = torch.dot(e1, e2) / (e1_norm * e2_norm)\n",
        "    return (1 - cosine_sim).item()\n",
        "\n",
        "for w1, w2 in word_pairs:\n",
        "    try:\n",
        "        emb1 = get_embedding(w1)\n",
        "        emb2 = get_embedding(w2)\n",
        "\n",
        "        euclidean_dist = euclidean_distance(emb1, emb2)\n",
        "        cos_dist = cosine_distance(emb1, emb2)\n",
        "\n",
        "        print(f\"{w1} - {w2} | Euclidean distance: {euclidean_dist:.4f} | Cosine distance: {cos_dist:.4f}\")\n",
        "\n",
        "    except Exception as e:\n",
        "        print(f\"Error processing ({w1}, {w2}): {e}\")"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "7cRbSQUPBGDg",
        "outputId": "46962d8f-15f7-4858-b7de-321a8506377f"
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "‡§Æ‡§æ‡§¨‡§ø - ‡§Æ‡§æ‡§≠‡•Ä‡§≠ | Euclidean distance: 7.4721 | Cosine distance: 0.0476\n",
            "‡§á‡§π‡•à‡§ß‡§ø - ‡§Ø‡§π‡•á‡§ß‡•Ä | Euclidean distance: 26.2521 | Cosine distance: 0.7530\n",
            "‡§á‡§∑‡•Å‡§∞‡§ø - ‡§á‡§∂‡•Ç‡§∞‡•Ä | Euclidean distance: 1.1191 | Cosine distance: 0.0008\n",
            "‡§â‡§¶‡•á‡§£‡•Ä - ‡§â‡§ß‡•á‡§®‡§ø | Euclidean distance: 3.0543 | Cosine distance: 0.0041\n",
            "‡§á‡§Ø‡§Æ‡§®‡•ç - ‡§Ø‡§Æ‡§®‡•ç‡§§ | Euclidean distance: 29.0171 | Cosine distance: 0.5585\n",
            "‡§®‡§µ‡§™‡•ç - ‡§™‡•ç‡§∞‡§æ‡§£ | Euclidean distance: 16.4873 | Cosine distance: 0.2162\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "results = []\n",
        "\n",
        "for w1, w2 in word_pairs:\n",
        "    try:\n",
        "        emb1 = get_embedding(w1)\n",
        "        emb2 = get_embedding(w2)\n",
        "\n",
        "        euclidean_dist = euclidean_distance(emb1, emb2)\n",
        "        cos_dist = cosine_distance(emb1, emb2)\n",
        "\n",
        "        results.append((w1, w2, euclidean_dist, cos_dist))\n",
        "        print(f\"{w1} - {w2} | Euclidean distance: {euclidean_dist:.4f} | Cosine distance: {cos_dist:.4f}\")\n",
        "\n",
        "    except Exception as e:\n",
        "        print(f\"Error processing ({w1}, {w2}): {e}\")"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "1uWSTEiGwJ61",
        "outputId": "89a808fa-336f-4101-fe8b-ed474d3cfe6a"
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "‡§Æ‡§æ‡§¨‡§ø - ‡§Æ‡§æ‡§≠‡•Ä‡§≠ | Euclidean distance: 7.4721 | Cosine distance: 0.0476\n",
            "‡§á‡§π‡•à‡§ß‡§ø - ‡§Ø‡§π‡•á‡§ß‡•Ä | Euclidean distance: 26.2521 | Cosine distance: 0.7530\n",
            "‡§á‡§∑‡•Å‡§∞‡§ø - ‡§á‡§∂‡•Ç‡§∞‡•Ä | Euclidean distance: 1.1191 | Cosine distance: 0.0008\n",
            "‡§â‡§¶‡•á‡§£‡•Ä - ‡§â‡§ß‡•á‡§®‡§ø | Euclidean distance: 3.0543 | Cosine distance: 0.0041\n",
            "‡§á‡§Ø‡§Æ‡§®‡•ç - ‡§Ø‡§Æ‡§®‡•ç‡§§ | Euclidean distance: 29.0171 | Cosine distance: 0.5585\n",
            "‡§®‡§µ‡§™‡•ç - ‡§™‡•ç‡§∞‡§æ‡§£ | Euclidean distance: 16.4873 | Cosine distance: 0.2162\n"
          ]
        }
      ]
    },
    {
      "cell_type": "markdown",
      "source": [
        "patience = 15 , ran for 32 epochs\n",
        "\n",
        "‡§Æ‡§æ‡§¨‡§ø - ‡§Æ‡§æ‡§≠‡•Ä‡§≠ | Euclidean distance: 1.7096\n",
        "‡§á‡§π‡•à‡§ß‡§ø - ‡§Ø‡§π‡•á‡§ß‡•Ä | Euclidean distance: 23.8212\n",
        "‡§á‡§∑‡•Å‡§∞‡§ø - ‡§á‡§∂‡•Ç‡§∞‡•Ä | Euclidean distance: 0.8615\n",
        "‡§â‡§¶‡•á‡§£‡•Ä - ‡§â‡§ß‡•á‡§®‡§ø | Euclidean distance: 2.3987\n",
        "‡§á‡§Ø‡§Æ‡§®‡•ç - ‡§Ø‡§Æ‡§®‡•ç‡§§ | Euclidean distance: 19.7186\n",
        "‡§®‡§µ‡§™‡•ç - ‡§™‡•ç‡§∞‡§æ‡§£ | Euclidean distance: 13.6405"
      ],
      "metadata": {
        "id": "0Cwc_iiIzzFd"
      }
    },
    {
      "cell_type": "markdown",
      "source": [
        "Patience = 20 epoxhs = 66\n",
        "‡§Æ‡§æ‡§¨‡§ø - ‡§Æ‡§æ‡§≠‡•Ä‡§≠ | Euclidean distance: 3.0111\n",
        "‡§á‡§π‡•à‡§ß‡§ø - ‡§Ø‡§π‡•á‡§ß‡•Ä | Euclidean distance: 40.7203\n",
        "‡§á‡§∑‡•Å‡§∞‡§ø - ‡§á‡§∂‡•Ç‡§∞‡•Ä | Euclidean distance: 2.1803\n",
        "‡§â‡§¶‡•á‡§£‡•Ä - ‡§â‡§ß‡•á‡§®‡§ø | Euclidean distance: 4.2947\n",
        "‡§á‡§Ø‡§Æ‡§®‡•ç - ‡§Ø‡§Æ‡§®‡•ç‡§§ | Euclidean distance: 42.0686\n",
        "‡§®‡§µ‡§™‡•ç - ‡§™‡•ç‡§∞‡§æ‡§£ | Euclidean distance: 22.1546"
      ],
      "metadata": {
        "id": "XEuOAz0p3xGs"
      }
    },
    {
      "cell_type": "markdown",
      "source": [
        "patience = 9, epochs = 44, Train Loss: 0.0002 | Val Loss: 0.0007\n",
        "\n",
        "‡§Æ‡§æ‡§¨‡§ø - ‡§Æ‡§æ‡§≠‡•Ä‡§≠ | Euclidean distance: 8.2003\n",
        "‡§á‡§π‡•à‡§ß‡§ø - ‡§Ø‡§π‡•á‡§ß‡•Ä | Euclidean distance: 27.1604\n",
        "‡§á‡§∑‡•Å‡§∞‡§ø - ‡§á‡§∂‡•Ç‡§∞‡•Ä | Euclidean distance: 2.3026\n",
        "‡§â‡§¶‡•á‡§£‡•Ä - ‡§â‡§ß‡•á‡§®‡§ø | Euclidean distance: 3.1128\n",
        "‡§á‡§Ø‡§Æ‡§®‡•ç - ‡§Ø‡§Æ‡§®‡•ç‡§§ | Euclidean distance: 26.4312\n",
        "‡§®‡§µ‡§™‡•ç - ‡§™‡•ç‡§∞‡§æ‡§£ | Euclidean distance: 13.2765"
      ],
      "metadata": {
        "id": "Wja5HVX86QsX"
      }
    },
    {
      "cell_type": "markdown",
      "source": [
        "patience = 9, epochs= 34\n",
        "\n",
        "* ‡§Æ‡§æ‡§¨‡§ø - ‡§Æ‡§æ‡§≠‡•Ä‡§≠ | Euclidean distance: 1.0501 | Cosine distance: 0.0014\n",
        "* ‡§á‡§π‡•à‡§ß‡§ø - ‡§Ø‡§π‡•á‡§ß‡•Ä | Euclidean distance: 20.9341 | Cosine distance: 0.9220\n",
        "* ‡§á‡§∑‡•Å‡§∞‡§ø - ‡§á‡§∂‡•Ç‡§∞‡•Ä | Euclidean distance: 0.8332 | Cosine distance: 0.0011\n",
        "* ‡§â‡§¶‡•á‡§£‡•Ä - ‡§â‡§ß‡•á‡§®‡§ø | Euclidean distance: 3.7462 | Cosine distance: 0.0195\n",
        "* ‡§á‡§Ø‡§Æ‡§®‡•ç - ‡§Ø‡§Æ‡§®‡•ç‡§§ | Euclidean distance: 21.4631 | Cosine distance: 0.4308\n",
        "* ‡§®‡§µ‡§™‡•ç - ‡§™‡•ç‡§∞‡§æ‡§£ | Euclidean distance: 12.6588 | Cosine distance: 0.1812\n",
        "\n"
      ],
      "metadata": {
        "id": "C1dCwGwwDYt0"
      }
    },
    {
      "cell_type": "markdown",
      "source": [
        "Patience = 9, epochs = 42\n",
        "* ‡§Æ‡§æ‡§¨‡§ø - ‡§Æ‡§æ‡§≠‡•Ä‡§≠ | Euclidean distance: 7.4721 | Cosine distance: 0.0476\n",
        "* ‡§á‡§π‡•à‡§ß‡§ø - ‡§Ø‡§π‡•á‡§ß‡•Ä | Euclidean distance: 26.2521 | Cosine distance: 0.7530\n",
        "* ‡§á‡§∑‡•Å‡§∞‡§ø - ‡§á‡§∂‡•Ç‡§∞‡•Ä | Euclidean distance: 1.1191 | Cosine distance: 0.0008\n",
        "* ‡§â‡§¶‡•á‡§£‡•Ä - ‡§â‡§ß‡•á‡§®‡§ø | Euclidean distance: 3.0543 | Cosine distance: 0.0041\n",
        "* ‡§á‡§Ø‡§Æ‡§®‡•ç - ‡§Ø‡§Æ‡§®‡•ç‡§§ | Euclidean distance: 29.0171 | Cosine distance: 0.5585\n",
        "* ‡§®‡§µ‡§™‡•ç - ‡§™‡•ç‡§∞‡§æ‡§£ | Euclidean distance: 16.4873 | Cosine distance: 0.2162"
      ],
      "metadata": {
        "id": "8hYf-LQXTiqa"
      }
    },
    {
      "cell_type": "code",
      "source": [],
      "metadata": {
        "id": "3sAu7HayzyRg"
      },
      "execution_count": null,
      "outputs": []
    }
  ]
}